{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import hacca\n",
    "from hacca import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from STalign import STalign\n",
    "## import dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import plotly\n",
    "import requests\n",
    "from STalign import STalign\n",
    "# make plots bigger\n",
    "import os, sys\n",
    "print(sys.executable) # works this time\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "import scanpy as sc\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from STalign import STalign\n",
    "## import dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import plotly\n",
    "import requests\n",
    "\n",
    "# make plots bigger\n",
    "import os, sys\n",
    "print(sys.executable) # works this time\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "import scanpy as sc\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(a,b_prime):\n",
    "    import matplotlib.pyplot as plt\n",
    "    xJ = a.D[:, 0]\n",
    "    yJ = a.D[:, 1]\n",
    "    xI = b_prime.D[:, 0]\n",
    "    yI = b_prime.D[:, 1]\n",
    "    XI,YI,I,fig = STalign.rasterize(xI,yI,dx=30,blur=1.5)\n",
    "    XJ,YJ,J,fig = STalign.rasterize(xJ,yJ,dx=30, blur=1.5)\n",
    "    extentI = STalign.extent_from_x((YI,XI))\n",
    "    extentJ = STalign.extent_from_x((YJ,XJ))\n",
    "    # run LDDMM\n",
    "    # specify device (default device for STalign.LDDMM is cpu)\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    \n",
    "    # keep all other parameters default\n",
    "    params = {\n",
    "                'niter': 1000,\n",
    "                'device':device,\n",
    "                'epV': 50\n",
    "              }\n",
    "    \n",
    "    out = STalign.LDDMM([YI,XI],I,[YJ,XJ],J,**params)\n",
    "    # get necessary output variables\n",
    "    A = out['A']\n",
    "    v = out['v']\n",
    "    xv = out['xv']\n",
    "    # set device for building tensors\n",
    "    if torch.cuda.is_available():\n",
    "        torch.set_default_device('cuda:0')\n",
    "    else:\n",
    "        torch.set_default_device('cpu')\n",
    "        # apply transform\n",
    "    phii = STalign.build_transform(xv,v,A,XJ=[YJ,XJ],direction='b')\n",
    "    phiI = STalign.transform_image_source_to_target(xv,v,A,[YI,XI],I,[YJ,XJ])\n",
    "    \n",
    "    #switch tensor from cuda to cpu for plotting with numpy\n",
    "    if phii.is_cuda:\n",
    "        phii = phii.cpu()\n",
    "    if phiI.is_cuda:\n",
    "        phiI = phiI.cpu()\n",
    "    # transform is invertible\n",
    "    phi = STalign.build_transform(xv,v,A,XJ=[YI,XI],direction='f')\n",
    "    phiiJ = STalign.transform_image_target_to_source(xv,v,A,[YJ,XJ],J,[YI,XI])\n",
    "    \n",
    "    #switch tensor from cuda to cpu for plotting with numpy\n",
    "    if phi.is_cuda:\n",
    "        phi = phi.cpu()\n",
    "    if phiiJ.is_cuda:\n",
    "        phiiJ = phiiJ.cpu()\n",
    "    # apply transform to original points\n",
    "    tpointsI= STalign.transform_points_source_to_target(xv,v,A, np.stack([yI, xI], 1).astype(np.double))\n",
    "    \n",
    "    #switch tensor from cuda to cpu for plotting with numpy\n",
    "    if tpointsI.is_cuda:\n",
    "        tpointsI = tpointsI.cpu()\n",
    "    \n",
    "    #switch from row column coordinates (y,x) to (x,y)\n",
    "    xI_LDDMM = tpointsI[:,1]\n",
    "    yI_LDDMM = tpointsI[:,0]\n",
    "    df3 = pd.DataFrame(\n",
    "    \n",
    "        {\n",
    "    \n",
    "            \"x\": xI_LDDMM,\n",
    "    \n",
    "            \"y\": yI_LDDMM,\n",
    "           \n",
    "        },\n",
    "    \n",
    "    )\n",
    "    b_prime.D=df3.to_numpy()\n",
    "   \n",
    "\n",
    "    return b_prime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAlign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [(f\"{prefix}1\", f\"{prefix}2\") for prefix in \"ABCDEFGHIJKLMN\"]\n",
    "base_path = \"I:/mutiomics/Spatial Multimodal Analysis of Transcriptomes and Metabolomes in Tissues/benchmark/merge\"\n",
    "STalign_alignment_work_dir = os.path.join(base_path, 'STalign')\n",
    "if not os.path.exists(STalign_alignment_work_dir):\n",
    "    os.makedirs(STalign_alignment_work_dir)\n",
    "accuracies = []\n",
    "for sample in samples:\n",
    "    print(f\"process {sample}\")\n",
    "    sample1 = sample[0]\n",
    "    sample2 = sample[1]\n",
    "    a_h5ad = sc.read_h5ad(os.path.join(base_path, sample1+\".h5ad\"))\n",
    "    b_prime_h5ad = sc.read_h5ad(os.path.join(base_path,sample2+\".h5ad\"))\n",
    "    a_h5ad.obs[\"leiden\"] = a_h5ad.obs[\"clusters\"]\n",
    "    b_prime_h5ad.obs[\"leiden\"] = b_prime_h5ad.obs[\"clusters\"]\n",
    "    b_prime_spatial = pd.DataFrame(b_prime_h5ad.obsm['spatial'])\n",
    "    scaledata = hacca.center_and_scale(b_prime_spatial)\n",
    "    b_prime_spatial = pd.DataFrame(scaledata, columns=b_prime_spatial.columns).to_numpy()\n",
    "    a_spatial = pd.DataFrame(a_h5ad.obsm['spatial'])\n",
    "    scaledata = hacca.center_and_scale(a_spatial)\n",
    "    a_spatial = pd.DataFrame(scaledata, columns=a_spatial.columns).to_numpy()\n",
    "    a = Data(X=a_h5ad.X.toarray(), D = a_spatial, Label=a_h5ad.obs['leiden'].to_numpy())\n",
    "    b_prime = Data(X=b_prime_h5ad.X.toarray(), D = b_prime_spatial, Label=b_prime_h5ad.obs['leiden'].to_numpy())\n",
    "    b_truth = a # use a as the ground truth to evaluate b_predict\n",
    "    _b_prime = process(a,b_prime)\n",
    "    b_predict = hacca.direct_alignment(a, _b_prime, STalign_alignment_work_dir)\n",
    "    pi = hacca.direct_alignment_metric(a, _b_prime)\n",
    "    hacca.plot_b_predict(b_predict, STalign_alignment_work_dir)\n",
    "    STalign_alignment_loss = hacca.loss(b_predict, b_truth)\n",
    "    STalign_pairwise_alignment_accuracy = hacca.pairwise_alignment_accuracy(a, _b_prime, pi)\n",
    "    print(f\"{sample}, {STalign_alignment_loss},{STalign_pairwise_alignment_accuracy}\")\n",
    "    accuracies.append([sample, STalign_alignment_loss, STalign_pairwise_alignment_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directalign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [(f\"{prefix}1\", f\"{prefix}2\") for prefix in \"ABCDEFGHIJKLMN\"]\n",
    "base_path = \"I:/mutiomics/Spatial Multimodal Analysis of Transcriptomes and Metabolomes in Tissues/benchmark/merge\"\n",
    "direct_alignment_work_dir = os.path.join(base_path, 'STalign')\n",
    "if not os.path.exists(direct_alignment_work_dir):\n",
    "    os.makedirs(direct_alignment_work_dir)\n",
    "Direct_accuracies = []\n",
    "for sample in samples:\n",
    "    print(f\"process {sample}\")\n",
    "    sample1 = sample[0]\n",
    "    sample2 = sample[1]\n",
    "    a_h5ad = sc.read_h5ad(os.path.join(base_path, sample1+\".h5ad\"))\n",
    "    b_prime_h5ad = sc.read_h5ad(os.path.join(base_path,sample2+\".h5ad\"))\n",
    "    a_h5ad.obs[\"leiden\"] = a_h5ad.obs[\"clusters\"]\n",
    "    b_prime_h5ad.obs[\"leiden\"] = b_prime_h5ad.obs[\"clusters\"]\n",
    "    b_prime_spatial = pd.DataFrame(b_prime_h5ad.obsm['spatial'])\n",
    "    scaledata = hacca.center_and_scale(b_prime_spatial)\n",
    "    b_prime_spatial = pd.DataFrame(scaledata, columns=b_prime_spatial.columns).to_numpy()\n",
    "    a_spatial = pd.DataFrame(a_h5ad.obsm['spatial'])\n",
    "    scaledata = hacca.center_and_scale(a_spatial)\n",
    "    a_spatial = pd.DataFrame(scaledata, columns=a_spatial.columns).to_numpy()\n",
    "    a = Data(X=a_h5ad.X.toarray(), D = a_spatial, Label=a_h5ad.obs['leiden'].to_numpy())\n",
    "    b_prime = Data(X=b_prime_h5ad.X.toarray(), D = b_prime_spatial, Label=b_prime_h5ad.obs['leiden'].to_numpy())\n",
    "    b_truth = a # use a as the ground truth to evaluate b_predict\n",
    "    b_predict = hacca.direct_alignment(a, b_prime, direct_alignment_work_dir)\n",
    "    pi = hacca.direct_alignment_metric(a, b_prime)\n",
    "    hacca.plot_b_predict(b_predict, direct_alignment_work_dir)\n",
    "    direct_alignment_loss = hacca.loss(b_predict, b_truth)\n",
    "    direct_alignment_pairwise_alignment_accuracy = hacca.pairwise_alignment_accuracy(a, b_prime, pi)\n",
    "    hacca.plot_b_predict(b_predict, STalign_alignment_work_dir)\n",
    "    print(f\"{sample}, {direct_alignment_loss},{direct_alignment_pairwise_alignment_accuracy}\")\n",
    "    Direct_accuracies.append([sample, direct_alignment_loss, direct_alignment_pairwise_alignment_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICP align"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [(f\"{prefix}1\", f\"{prefix}2\") for prefix in \"ABCDEFGHIJKLMN\"]\n",
    "base_path = \"I:/mutiomics/Spatial Multimodal Analysis of Transcriptomes and Metabolomes in Tissues/benchmark/merge\"\n",
    "icp_2d_work_dir = os.path.join(base_path, 'ICP2D')\n",
    "if not os.path.exists(icp_2d_work_dir):\n",
    "    os.makedirs(icp_2d_work_dir)\n",
    "Direct_accuracies = []\n",
    "for sample in samples:\n",
    "    print(f\"process {sample}\")\n",
    "    sample1 = sample[0]\n",
    "    sample2 = sample[1]\n",
    "    a_h5ad = sc.read_h5ad(os.path.join(base_path, sample1+\".h5ad\"))\n",
    "    b_prime_h5ad = sc.read_h5ad(os.path.join(base_path,sample2+\".h5ad\"))\n",
    "    a_h5ad.obs[\"leiden\"] = a_h5ad.obs[\"clusters\"]\n",
    "    b_prime_h5ad.obs[\"leiden\"] = b_prime_h5ad.obs[\"clusters\"]\n",
    "    b_prime_spatial = pd.DataFrame(b_prime_h5ad.obsm['spatial'])\n",
    "    scaledata = hacca.center_and_scale(b_prime_spatial)\n",
    "    b_prime_spatial = pd.DataFrame(scaledata, columns=b_prime_spatial.columns).to_numpy()\n",
    "    a_spatial = pd.DataFrame(a_h5ad.obsm['spatial'])\n",
    "    scaledata = hacca.center_and_scale(a_spatial)\n",
    "    a_spatial = pd.DataFrame(scaledata, columns=a_spatial.columns).to_numpy()\n",
    "    a = Data(X=a_h5ad.X.toarray(), D = a_spatial, Label=a_h5ad.obs['leiden'].to_numpy())\n",
    "    b_prime = Data(X=b_prime_h5ad.X.toarray(), D = b_prime_spatial, Label=b_prime_h5ad.obs['leiden'].to_numpy())\n",
    "    b_truth = a # use a as the ground truth to evaluate b_predict\n",
    "    _b_prime = hacca.icp_2d_alignment(a, b_prime, icp_2d_work_dir)\n",
    "    b_predict = hacca.direct_alignment(a, _b_prime, work_dir=icp_2d_work_dir)\n",
    "    hacca.plot_b_predict(b_predict, icp_2d_work_dir)\n",
    "    pi = hacca.direct_alignment_metric(a, _b_prime)\n",
    "    icp_2d_loss = hacca.loss(b_predict, b_truth)\n",
    "    ICP2D_pairwise_alignment_accuracy = hacca.pairwise_alignment_accuracy(a, _b_prime, pi)\n",
    "    hacca.plot_b_predict(b_predict, STalign_alignment_work_dir)\n",
    "    print(f\"{sample}, {icp_2d_loss},{ICP2D_pairwise_alignment_accuracy}\")\n",
    "    Direct_accuracies.append([sample, icp_2d_loss, ICP2D_pairwise_alignment_accuracy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "haCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [(f\"{prefix}1\", f\"{prefix}2\") for prefix in \"M\"]\n",
    "base_path = \"I:/mutiomics/Spatial Multimodal Analysis of Transcriptomes and Metabolomes in Tissues/benchmark/merge\"\n",
    "haCCA_work_dir = os.path.join(base_path, 'haCCA')\n",
    "if not os.path.exists(haCCA_work_dir):\n",
    "    os.makedirs(haCCA_work_dir)\n",
    "Direct_accuracies = []\n",
    "for sample in samples:\n",
    "    print(f\"process {sample}\")\n",
    "    sample1 = sample[0]\n",
    "    sample2 = sample[1]\n",
    "    a_h5ad = sc.read_h5ad(os.path.join(base_path, sample1+\".h5ad\"))\n",
    "    b_prime_h5ad = sc.read_h5ad(os.path.join(base_path,sample2+\".h5ad\"))\n",
    "    a_h5ad.obs[\"leiden\"] = a_h5ad.obs[\"clusters\"]\n",
    "    b_prime_h5ad.obs[\"leiden\"] = b_prime_h5ad.obs[\"clusters\"]\n",
    "    b_prime_spatial = pd.DataFrame(b_prime_h5ad.obsm['spatial'])\n",
    "    scaledata = hacca.center_and_scale(b_prime_spatial)\n",
    "    b_prime_spatial = pd.DataFrame(scaledata, columns=b_prime_spatial.columns).to_numpy()\n",
    "    a_spatial = pd.DataFrame(a_h5ad.obsm['spatial'])\n",
    "    scaledata = hacca.center_and_scale(a_spatial)\n",
    "    a_spatial = pd.DataFrame(scaledata, columns=a_spatial.columns).to_numpy()\n",
    "    a = Data(X=a_h5ad.X.toarray(), D = a_spatial, Label=a_h5ad.obs['leiden'].to_numpy())\n",
    "    b_prime = Data(X=b_prime_h5ad.X.toarray(), D = b_prime_spatial, Label=b_prime_h5ad.obs['leiden'].to_numpy())\n",
    "    b_truth = a # use a as the ground truth to evaluate b_predict\n",
    "\n",
    "    _b_prime = hacca.manual_gross_alignment(a, b_prime, work_dir=haCCA_work_dir)\n",
    "    _b_prime = hacca.further_alignment(a, _b_prime)\n",
    "    _a, _b_prime = hacca.icp_2d_with_feature_alignment(a, _b_prime, dist_min=1, simpson_index_threshold=0.8)\n",
    "    b_preidct = hacca.direct_alignment(_a, _b_prime, work_dir=haCCA_work_dir)\n",
    "    b_predict_metric = hacca.direct_alignment_metric(_a, _b_prime)\n",
    "    haCCA = hacca.loss(b_preidct, b_truth)\n",
    "    hacca.plot_b_predict(b_preidct,haCCA_work_dir)\n",
    "    hacca_pairwise_alignment_accuracy = hacca.pairwise_alignment_accuracy(_a, _b_prime, b_predict_metric)\n",
    "    print(f\"{sample}, {haCCA},{hacca_pairwise_alignment_accuracy}\")\n",
    "    Direct_accuracies.append([sample, haCCA, hacca_pairwise_alignment_accuracy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directalign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [(f\"{prefix}1\", f\"{prefix}2\") for prefix in \"LMN\"]\n",
    "base_path = \"I:/mutiomics/Spatial Multimodal Analysis of Transcriptomes and Metabolomes in Tissues/benchmark/merge\"\n",
    "manual_alignment_work_dir = os.path.join(base_path, 'manual_alignment')\n",
    "if not os.path.exists(manual_alignment_work_dir):\n",
    "    os.makedirs(manual_alignment_work_dir)\n",
    "Direct_accuracies = []\n",
    "for sample in samples:\n",
    "    print(f\"process {sample}\")\n",
    "    sample1 = sample[0]\n",
    "    sample2 = sample[1]\n",
    "    a_h5ad = sc.read_h5ad(os.path.join(base_path, sample1+\".h5ad\"))\n",
    "    b_prime_h5ad = sc.read_h5ad(os.path.join(base_path,sample2+\".h5ad\"))\n",
    "    a_h5ad.obs[\"leiden\"] = a_h5ad.obs[\"clusters\"]\n",
    "    b_prime_h5ad.obs[\"leiden\"] = b_prime_h5ad.obs[\"clusters\"]\n",
    "    b_prime_spatial = pd.DataFrame(b_prime_h5ad.obsm['spatial'])\n",
    "    scaledata = hacca.center_and_scale(b_prime_spatial)\n",
    "    b_prime_spatial = pd.DataFrame(scaledata, columns=b_prime_spatial.columns).to_numpy()\n",
    "    a_spatial = pd.DataFrame(a_h5ad.obsm['spatial'])\n",
    "    scaledata = hacca.center_and_scale(a_spatial)\n",
    "    a_spatial = pd.DataFrame(scaledata, columns=a_spatial.columns).to_numpy()\n",
    "    a = Data(X=a_h5ad.X.toarray(), D = a_spatial, Label=a_h5ad.obs['leiden'].to_numpy())\n",
    "    b_prime = Data(X=b_prime_h5ad.X.toarray(), D = b_prime_spatial, Label=b_prime_h5ad.obs['leiden'].to_numpy())\n",
    "    b_truth = a # use a as the ground truth to evaluate b_predict\n",
    "\n",
    "    _b_prime = hacca.manual_gross_alignment(a, b_prime, work_dir=manual_alignment_work_dir)\n",
    "    _b_prime = hacca.further_alignment(a, _b_prime)\n",
    "    manual_alignment = hacca.loss(b_preidct, b_truth)\n",
    "    manual_alignment_pairwise_alignment_accuracy = hacca.pairwise_alignment_accuracy(a, _b_prime, pi)\n",
    "    print(f\"{sample}, {manual_alignment},{manual_alignment_pairwise_alignment_accuracy}\")\n",
    "    Direct_accuracies.append([sample, manual_alignment, manual_alignment_pairwise_alignment_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_df = pd.DataFrame(Direct_accuracies, columns=['Sample', 'Alignment_Loss', 'Pairwise_Alignment_Accuracy'])\n",
    "accuracies_df[['Alignment_Loss_1', 'Alignment_Loss_2', 'Alignment_Loss_3']] = pd.DataFrame(accuracies_df['Alignment_Loss'].tolist(), index=accuracies_df.index)\n",
    "accuracies_df.drop(columns=['Alignment_Loss'], inplace=True)\n",
    "accuracies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = hacca.direct_alignment_metric(a, _b_prime)\n",
    "hacca.plot_b_predict(b_predict, STalign_alignment_work_dir)\n",
    "STalign_alignment_loss = hacca.loss(b_predict, b_truth)\n",
    "STalign_pairwise_alignment_accuracy = hacca.pairwise_alignment_accuracy(a, _b_prime, pi)\n",
    "print(f\"Run STalign_alignment: loss: {STalign_alignment_loss}, pairwise_alignment_accuracy: {STalign_pairwise_alignment_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
